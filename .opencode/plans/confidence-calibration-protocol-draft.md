# Confidence Calibration Protocol - BOFU Tool Draft

**Target Location:** `/home/debianvm/brainium/brainium.ai/content/frameworks/confidence-calibration-protocol.md`

**Funnel Stage:** BOFU (Bottom of Funnel - Solution/Action)
**Cluster:** Microsoft Critical Thinking
**Estimated Length:** 1200-1500 words

---

## Front Matter

```yaml
---
title: "Confidence Calibration Protocol"
description: "A systematic approach to maintaining critical thinking while using AI. Based on Microsoft's research showing that confidence mismatch—not AI itself—determines analytical engagement."
date: 2026-01-31
tags: ["frameworks", "critical-thinking", "confidence-calibration", "ai-assisted-work", "microsoft-study"]
related_research:
  - "Microsoft critical thinking survey (2025)"
related_tools:
  - "Think First Protocol"
funnel_stage: "bofu"
cluster: "microsoft-critical-thinking"
---
```

---

## Content Outline

### 1. The Confidence Paradox (Hook)
- Microsoft's finding: AI doesn't eliminate critical thinking, makes it conditional
- The drift pattern: confidence in AI grows, confidence in self erodes
- The protocol interrupts this drift

### 2. Core Principle
- Critical thinking activates on confidence mismatch
- Protocol engineers mismatches deliberately

### 3. The Protocol - 4 Tactics

**Tactic 1: The Confidence Check (Pre-Acceptance)**
- Rate AI confidence (1-5) and self-confidence (1-5)
- If gap ≥2 points, trigger 2-minute verification
- Example with code review scenario

**Tactic 2: The Explanation Requirement (Process Verification)**
- Ask for step-by-step reasoning, not just answers
- Three-Question Filter (assumptions, evidence, failure modes)
- Anti-pattern: accepting eloquent outputs you can't explain

**Tactic 3: Task-Type Matching (Risk-Adjusted Scrutiny)**
- Advice tasks (highest risk) = maximum scrutiny
- Creation tasks (high risk, foundational) = structural review  
- Information tasks (medium) = spot-checking
- Transformation tasks (low) = minimal verification
- Key insight: creation tasks showed LEAST critical thinking in study

**Tactic 4: The Weekly Confidence Audit (Drift Detection)**
- 15 minutes every Friday
- Review 3 tasks (high/medium/low stakes)
- Rate trends and set one adjustment

### 4. Implementation Templates
- Daily Confidence Log (2 min/task)
- Weekly Audit Template (15 min)

### 5. Anti-Patterns Table
- Confidence Inflation
- Verification Theater
- Task-Type Blindness
- Drift Denial
- Confidence Collapse

### 6. Integration with Other Tools
- Think First Protocol
- Active Prompting Protocol
- Retrieval Practice

### 7. Indicators (Calibrated vs Drifting)

### 8. Research Connection
- Links back to Microsoft study findings

### 9. Next Steps + CTA to Field Note

---

## Cross-Links Required

**From this tool to:**
- `/research/microsoft-critical-thinking-2025/` (research foundation)
- `/field-notes/confidence-calibration-experiment/` (validation - CTA at end)
- `/frameworks/think-first-protocol/` (integration)
- `/cognitive-tools/ai-assisted-learning/` (coding domain)

**To this tool from:**
- `/essays/why-you-trust-ai-more-than-yourself/` (add CTA at end)
- `/research/microsoft-critical-thinking-2025/` (add link in "Four Tactics" section)
- `/frameworks/_index.md` (add to Available Frameworks)

---

## Quality Checklist

- [ ] 30-minute implementable? Yes—tactics can be applied immediately
- [ ] Named framework? Yes—"Confidence Calibration Protocol"
- [ ] Anti-patterns included? Yes—5 patterns in table format
- [ ] Links to 2+ research pieces? Yes—Microsoft study + triangulation with others
- [ ] Clear CTA? Yes—"Read the field note" for validation
- [ ] Follows content-standards.md tone guidelines? Yes—curious, not alarmist
