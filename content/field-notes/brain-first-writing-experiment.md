---
title: "Field Notes: 30 Days of Brain-First Writing"
description: "I tested the Cognitive Debt framework from MIT's study on my own technical writing. Here's what worked, what failed, and the unexpected benefit I didn't anticipate."
date: 2026-01-31
tags: ["field-notes", "cognitive-debt", "writing", "experiments"]
related_research:
  - "MIT cognitive debt study (2025)"
related_tools:
  - "Brain-First Draft protocol"
  - "Active Monitoring"
reading_time: "4 minutes"
---

## What I Tried

After reading the MIT study on cognitive debt, I committed to 30 days of brain-first writing. No AI assistance until I had at least 20 minutes of unassisted work on the page.

**The Setup:**
- 12 writing sessions over 30 days
- Mix of technical documentation, essays, and email
- Tracked: word count, perceived difficulty, end quality, and ownership (could I explain it without notes?)

**The Rules:**
1. Timer set for 20 minutes minimum of unassisted writing
2. AI allowed only after the timer, and only for refinement
3. One weekly "pure" session with no AI at all
4. End each session with a 2-minute memory summary (no looking at the text)

---

## Week 1: The Resistance Was Real

The first three sessions felt like dragging my brain through mud. I was used to starting with AI—tossing a prompt, getting a draft, then editing. Starting with my own thoughts felt slow and painful.

**Session 1 (Technical doc):** Wrote 340 words in 20 minutes. Fragmented. Jumped between ideas. By the end I had three disconnected paragraphs that barely hung together.

**Session 2 (Essay draft):** Better. 520 words. Still messy, but I noticed something: the argument structure was clearer *to me*. I knew what I was trying to say, even if I hadn't said it elegantly yet.

**Session 3 (Pure, no AI):** Disaster. 280 words. I hit a wall 15 minutes in and couldn't push through. Ended early, frustrated.

**Retrieval test (end of week):** I could summarize the technical doc accurately. The essay, somewhat. The pure session? Barely remembered the topic.

**Lesson:** The 20-minute minimum isn't arbitrary. Session 3 failed because I didn't push through the resistance phase.

---

## Week 2: Finding the Pattern

I started to notice something. The first 10-15 minutes of brain-first writing were always hard. But around minute 18-20, something shifted. Ideas started connecting. The writing felt less like extraction and more like flow.

**Session 4 (Technical doc):** 25 minutes unassisted, then AI for polish. The AI suggestions made *sense* this time—I could evaluate them against my own mental model. Accepted 60%, rejected 40% with specific reasoning.

**Session 5 (Essay):** Tried alternating paragraphs (brain-first, then AI-assisted). This was the worst approach. The tone shifted jarringly. The AI paragraphs were smoother but said less. I ended up rewriting them from scratch.

**Session 6 (Pure):** 420 words. Still hard, but I pushed through the 15-minute wall. The writing was simpler, more direct. No fancy phrasing, but clear thinking.

**Unexpected finding:** My memory summaries were getting longer and more accurate. By session 6, I could quote specific phrases I'd written from memory—not because I memorized them, but because I'd *thought* them through instead of outsourcing the thinking.

---

## Week 3: The Ownership Shift

This was the week I started feeling different about the work.

**Session 7 (Email campaign):** Short pieces, so I did them all brain-first. Usually I'd AI these for efficiency. Instead, I wrote 8 emails in 45 minutes. They weren't as polished, but they sounded like *me*. When I reviewed them later, I recognized my own voice. That's the ownership the study mentioned.

**Session 8 (Long-form essay):** First time trying the Retrieval Practice Protocol. After finishing with AI assistance, I closed everything and waited 10 minutes. Then wrote a summary from memory.

The gaps were embarrassing. I'd accepted AI suggestions for two sections that I couldn't actually explain. I went back, removed them, and wrote my own versions. Simpler, but *mine*.

**Session 9 (Pure):** Best session yet. 680 words in 30 minutes. The pure sessions were getting easier—not because the writing was better, but because my tolerance for the initial discomfort had increased.

---

## Week 4: Integration and Honest Assessment

**What Worked:**

1. **The 20-minute minimum is non-negotiable.** Every good session started with discomfort that resolved around minute 18. Skipping this meant fragmented thinking.

2. **Memory summaries exposed the gaps.** I caught myself accepting AI text I didn't understand at least 5 times. The protocol works.

3. **Weekly pure sessions inoculated against atrophy.** By week 4, unassisted writing felt *normal* again, not foreign.

4. **Ownership is real and measurable.** I could present the brain-first pieces without notes. The AI-heavy pieces from before the experiment? I had to re-read them to remember what I'd "written."

**What Failed:**

1. **Alternating AI and brain-first in the same piece.** Tone inconsistency was a real problem. The framework works best when phases are sequential: human first, AI second.

2. **Using AI for "unsticking" before the 20-minute mark.** I tried this twice and both times ended up with AI-generated text that didn't match my intent. Better to push through the stuckness.

3. **The protocol doesn't work for routine tasks.** Updating a procedures doc or writing a standard email? The overhead wasn't worth it. I reserve brain-first for creative or high-stakes writing now.

**The Unexpected Benefit:**

My *editing* got faster. When I started brain-first, I already knew the argument structure. I could evaluate AI suggestions instantly—yes, this fits; no, that's off track. Before, I'd spend 20 minutes reading and rereading AI drafts to figure out if they were any good.

---

## The Honest Numbers

| Metric | Before (AI-first) | After (Brain-first) |
|--------|-------------------|---------------------|
| Total writing time per piece | 45 min | 55 min |
| Editing/revision time | 35 min | 15 min |
| Ownership (1-10 scale) | 4 | 8 |
| Memory accuracy (retrieval test) | 40% | 85% |
| End quality (self-rated) | 7/10 | 8/10 |

**Net result:** Slightly more total time, but dramatically higher ownership and less revision hell. Worth it.

---

## What I'll Keep Doing

1. **20-minute brain-first minimum** for any piece I need to truly understand or present
2. **Weekly pure session** (no AI at all) to maintain unassisted capability
3. **Retrieval practice** after AI-assisted work—catches the gaps every time
4. **Permission to AI-first for routine** admin work where ownership doesn't matter

---

## Suggested Next Steps

The Cognitive Debt framework worked for writing. Now I'm curious if the same pattern applies to other domains. Next experiment: applying brain-first principles to coding with the [Active Prompting Protocol](/cognitive-tools/ai-assisted-learning/).

The MIT study showed cognitive debt accumulates across domains. If the writing protocol works for coding too, we might have a generalizable strategy for AI-assisted cognition.

---

**Further Reading:**
- [MIT Cognitive Debt Study](/research/mit-cognitive-debt-2025/) — The research that started this experiment
- [Cognitive Offloading Essay](/essays/cognitive-offloading-research/) — The 40-year pattern behind skill decay
- [Active Prompting Protocol](/cognitive-tools/ai-assisted-learning/) — Next experiment: coding

**Questions for Follow-Up:**
- Does the 20-minute minimum hold for coding, or is the threshold different?
- How long can I go between pure sessions before atrophy kicks in?
- Can I develop a "debt detection" signal before I accept AI suggestions?
